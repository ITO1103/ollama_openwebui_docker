version: '3.4'

# ///////////   LINUX ONLY   ////////////
# Steps To Run LINUX with gpu Acceleration (need ROOT access like = sudo docker compose up)
# 1. Install Docker and NVIDIA Container Toolkit
#  https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html
# sudo apt-get install -y nvidia-container-toolkit
# sudo nvidia-ctk runtime configure --runtime=docker
# sudo systemctl restart docker


# test if GPU acceleration is available
#  firs RUN:  docker pull nvidia/cuda:12.8.1-runtime-ubuntu24.04
#  next To test if GPU acceleration is available, run the following command:

#  For cuda 12.8 use this command:
#  sudo docker run --rm --gpus all   nvidia/cuda:12.8.1-runtime-ubuntu24.04 nvidia-smi

# For cuda 12.2 use this command:
#  sudo docker run --rm --gpus all   nvidia/cuda:11.6.2-base-ubuntu20.04 nvidia-smi

#  FINALLY RUN: sudo docker compose up


# COMUN ERROR:
# When your pc is on sleep mode or hibernation mode, the GPU will not be available for docker containers.
# 1. Check if the GPU is available by running the following command:
#  nvidia-smi
# 2. If the GPU is still not available, restart the nvidia_uvm module by running the following command:
#  sudo rmmod nvidia_uvm && sudo modprobe nvidia_uvm
# 3 Restart Your PC :D



# //////////////////////////////////////////////////////////////////

services:
    openwebui:
        image: ghcr.io/open-webui/open-webui:v0.6.5
        restart: unless-stopped
        depends_on:
            - ollamadeepseek
            - mcpo
        ports:
           - '8333:8080'
        volumes:
          - './open-webui:/app/backend/data'
        environment:
            OLLAMA_BASE_URL: http://ollamadeepseek:11434 

    # Run dockerFile of MCPO 
    mcpo:
      build:
        context: mcpo
        dockerfile: Dockerfile
      ports:
        - '8334:8000'
      

    ollamadeepseek: 
        build:
            context: .
            dockerfile: Dockerfile
        # user: root # only for Linux
        restart: unless-stopped
        ports:
           - '11434:11434'
        volumes:
          - './ollama:/root/.ollama'
        environment:
            OLLAMA_HOST: 0.0.0.0
            OLLAMA_PORT: 11434
            OLLAMA_MODELS: 
            NVIDIA_VISIBLE_DEVICES: all
            NVIDIA_DRIVER_CAPABILITIES: all,utility
        runtime: nvidia
        deploy:
          resources:
            reservations:
              devices:
                - driver: nvidia
                  count: all
                  capabilities: [gpu]
        